name: Weekly AWS Resource Monitor

on:
  schedule:
    # Run every Monday at 9:00 AM UTC (1:00 AM PST / 4:00 AM EST)
    - cron: '0 9 * * 1'
  workflow_dispatch:  # Allow manual triggering

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: us-west-2

jobs:
  scan-dev-environment:
    name: Scan Dev Environment
    runs-on: ubuntu-latest
    outputs:
      results: ${{ steps.scan.outputs.results }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements-monitor.txt

      - name: Assume AWS Dev role
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: arn:aws:iam::477873552632:role/devops-deploy-role
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS identity
        run: |
          aws sts get-caller-identity

      - name: Scan Dev resources
        id: scan
        run: |
          python3 -u aws_resource_monitor.py \
            --skip-slack \
            --skip-csv \
            --dev-profile "" \
            --environments dev \
            --region ${{ env.AWS_REGION }} \
            --output-json dev_results.json

          # Output JSON results for next job (compact, single line)
          RESULTS=$(cat dev_results.json | jq -c '.')
          echo "results=$RESULTS" >> $GITHUB_OUTPUT
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
          GITHUB_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

  scan-stage-environment:
    name: Scan Stage Environment
    runs-on: ubuntu-latest
    needs: scan-dev-environment
    outputs:
      results: ${{ steps.scan.outputs.results }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements-monitor.txt

      - name: Assume AWS Stage role
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: arn:aws:iam::221203628080:role/devops-deploy-role
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS identity
        run: |
          aws sts get-caller-identity

      - name: Scan Stage resources
        id: scan
        run: |
          python3 -u aws_resource_monitor.py \
            --skip-slack \
            --skip-csv \
            --stage-profile "" \
            --environments stage \
            --region ${{ env.AWS_REGION }} \
            --output-json stage_results.json

          # Output JSON results for next job (compact, single line)
          RESULTS=$(cat stage_results.json | jq -c '.')
          echo "results=$RESULTS" >> $GITHUB_OUTPUT
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
          GITHUB_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

  scan-prod-environment:
    name: Scan Prod Environment
    runs-on: ubuntu-latest
    needs: scan-stage-environment
    outputs:
      results: ${{ steps.scan.outputs.results }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements-monitor.txt

      - name: Assume AWS Prod role
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: arn:aws:iam::947618278001:role/devops-deploy-role
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS identity
        run: |
          aws sts get-caller-identity

      - name: Scan Prod resources
        id: scan
        run: |
          python3 -u aws_resource_monitor.py \
            --skip-slack \
            --skip-csv \
            --prod-profile "" \
            --environments prod \
            --region ${{ env.AWS_REGION }} \
            --output-json prod_results.json

          # Output JSON results for next job (compact, single line)
          RESULTS=$(cat prod_results.json | jq -c '.')
          echo "results=$RESULTS" >> $GITHUB_OUTPUT
        env:
          AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
          GITHUB_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

  notify-completion:
    name: Notify Scan Completion
    runs-on: ubuntu-latest
    needs: [scan-dev-environment, scan-stage-environment, scan-prod-environment]
    if: always()
    steps:
      - name: Send detailed Slack notification
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK_URL }}
          DEV_RESULTS: ${{ needs.scan-dev-environment.outputs.results }}
          STAGE_RESULTS: ${{ needs.scan-stage-environment.outputs.results }}
          PROD_RESULTS: ${{ needs.scan-prod-environment.outputs.results }}
        run: |
          # Function to calculate percentage
          calc_percent() {
            local num=$1
            local denom=$2
            if [ "$denom" -eq 0 ]; then
              echo "0"
            else
              echo "scale=1; ($num * 100) / $denom" | bc
            fi
          }

          # Function to format environment results
          format_env_results() {
            local env_name=$1
            local results=$2
            local status=$3

            if [ "$status" != "success" ] || [ -z "$results" ]; then
              echo "*${env_name} Scan:* :x: Failed to retrieve results"
              return
            fi

            # Parse JSON values
            lambda_total=$(echo "$results" | jq -r ".${env_name,,}.lambda.total_functions // 0")
            lambda_bloated=$(echo "$results" | jq -r ".${env_name,,}.lambda.version_bloat_count // 0")
            lambda_unused=$(echo "$results" | jq -r ".${env_name,,}.lambda.unused_count // 0")
            lambda_storage=$(echo "$results" | jq -r ".${env_name,,}.lambda.total_storage_gb // 0")
            lambda_limit=$(echo "$results" | jq -r ".${env_name,,}.lambda.storage_limit_gb // 300")
            iam_total=$(echo "$results" | jq -r ".${env_name,,}.iam.total_roles // 0")
            iam_quota=$(echo "$results" | jq -r ".${env_name,,}.iam.roles_quota // 1000")
            rds_underused=$(echo "$results" | jq -r ".${env_name,,}.rds.underused_count // 0")
            rds_total=$(echo "$results" | jq -r ".${env_name,,}.rds.total_instances // 0")
            logs_old=$(echo "$results" | jq -r ".${env_name,,}.logs.old_log_groups_count // 0")
            logs_total=$(echo "$results" | jq -r ".${env_name,,}.logs.total_log_groups // 0")

            # Calculate percentages
            iam_percent=$(calc_percent $iam_total $iam_quota)
            lambda_storage_percent=$(calc_percent ${lambda_storage%.*} $lambda_limit)
            lambda_bloat_percent=$(calc_percent $lambda_bloated $lambda_total)
            lambda_unused_percent=$(calc_percent $lambda_unused $lambda_total)
            rds_percent=$(calc_percent $rds_underused $rds_total)
            logs_percent=$(calc_percent $logs_old $logs_total)

            echo "*${env_name} Scan:*"
            echo "• IAM Roles: ${iam_percent}% of 100% (${iam_total}/${iam_quota})"
            echo "• Lambda Storage: ${lambda_storage_percent}% of 100% (${lambda_storage}/${lambda_limit} GB)"
            echo "• Bloated Lambdas: ${lambda_bloat_percent}% (${lambda_bloated}/${lambda_total})"
            echo "• Unused Lambdas: ${lambda_unused_percent}% (${lambda_unused}/${lambda_total})"
            echo "• Underused RDS: ${rds_percent}% (${rds_underused}/${rds_total})"
            echo "• Old CloudWatch Logs: ${logs_percent}% (${logs_old}/${logs_total})"
          }

          # Build message for each environment
          DEV_MSG=$(format_env_results "DEV" "$DEV_RESULTS" "${{ needs.scan-dev-environment.result }}")
          STAGE_MSG=$(format_env_results "STAGE" "$STAGE_RESULTS" "${{ needs.scan-stage-environment.result }}")
          PROD_MSG=$(format_env_results "PROD" "$PROD_RESULTS" "${{ needs.scan-prod-environment.result }}")

          # Determine overall status
          if [ "${{ needs.scan-dev-environment.result }}" == "success" ] && [ "${{ needs.scan-stage-environment.result }}" == "success" ] && [ "${{ needs.scan-prod-environment.result }}" == "success" ]; then
            HEADER=":chart_with_upwards_trend: Weekly AWS Resource Monitor Scan Complete"
            COLOR="good"
          else
            HEADER=":warning: Weekly AWS Resource Monitor Scan - Some Environments Failed"
            COLOR="warning"
          fi

          # Create the Slack message using blocks for better formatting
          cat > /tmp/slack_payload.json << 'PAYLOAD_EOF'
          {
            "blocks": [
              {
                "type": "header",
                "text": {
                  "type": "plain_text",
                  "text": "HEADER_PLACEHOLDER",
                  "emoji": true
                }
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*Report Date:* TIMESTAMP_PLACEHOLDER"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "DEV_PLACEHOLDER"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "STAGE_PLACEHOLDER"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "PROD_PLACEHOLDER"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "context",
                "elements": [
                  {
                    "type": "mrkdwn",
                    "text": ":information_source: *Definitions:* Bloated Lambdas = >10 versions | Underused RDS = avg CPU <10% (7 days) | Old Logs = inactive >12 months"
                  }
                ]
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*:bulb: Recommendations:*\n• *Delete unused IAM roles* to stay within quota limits and improve security posture\n• *Clean up old Lambda versions* - keep only 2-3 recent versions to reduce storage bloat\n• *Delete unused CloudWatch log groups* (>12 months old) to reduce storage costs\n• *Review underused RDS instances* - consider downsizing or consolidating\n  └ <https://app.datadoghq.com/dashboard/9ij-isf-e39/overprovisioned-rds?fromUser=false&offset=0&refresh_mode=yearly&from_ts=1767254400000&to_ts=1767628625022&live=true|View Overprovisioned RDS Dashboard>"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*:moneybag: Understanding AWS Costs:*\n• To understand the cost on AWS resources, please use AWS Cost Explorer\n  └ <https://guild-education.atlassian.net/wiki/spaces/DEVOPS/pages/4582638174/AWS+Cost+Explorer+How+to+Analyze+Cloud+Costs|AWS Cost Explorer Guide>\n• To understand the cost on RDS particularly, refer to this Datadog dashboard\n  └ <https://app.datadoghq.com/cost/analyze/explorer?query=sum%3Aaws.cost.net.amortized.shared.resources.allocated%7Bservicename%3Ards%20AND%20aws_usage_type%3AUSW2-ExtendedSupport%3A%2A%20AND%20aws_cost_type%20IN%20%28Usage%2CDiscountedUsage%2CSavingsPlanCoveredUsage%29%20AND%20NOT%20aws_product%3Asupportenterprise%7D%20by%20%7Bteam%7D.rollup%28sum%2C%20weekly%29&anomaliesOnly=false&displayType=bars&filterRecent=false&measureType=absolute&tableViewType=breakdown&timeframeRefreshMode=paused&start=1756684800000&end=1765497599000&paused=true|RDS Cost Analysis by Team>"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "context",
                "elements": [
                  {
                    "type": "mrkdwn",
                    "text": "GITHUB_LINK_PLACEHOLDER"
                  }
                ]
              }
            ]
          }
          PAYLOAD_EOF

          # Replace placeholders
          TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S UTC')
          GITHUB_LINK="<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View workflow run>"

          # Use jq to properly escape and replace values
          # Block indices: 0=header, 1=date, 2=divider, 3=dev, 4=divider, 5=stage, 6=divider, 7=prod, 8=divider, 9=definitions, 10=divider, 11=recommendations, 12=divider, 13=costs, 14=divider, 15=github_link
          jq --arg header "$HEADER" \
             --arg timestamp "$TIMESTAMP" \
             --arg dev "$DEV_MSG" \
             --arg stage "$STAGE_MSG" \
             --arg prod "$PROD_MSG" \
             --arg github_link "$GITHUB_LINK" \
             '.blocks[0].text.text = $header |
              .blocks[1].text.text = ("*Report Date:* " + $timestamp) |
              .blocks[3].text.text = $dev |
              .blocks[5].text.text = $stage |
              .blocks[7].text.text = $prod |
              .blocks[15].elements[0].text = $github_link' \
             /tmp/slack_payload.json > /tmp/slack_final.json

          # Send to Slack
          curl -X POST "$SLACK_WEBHOOK" \
            -H 'Content-Type: application/json' \
            -d @/tmp/slack_final.json
