name: Monday Slack Notification

on:
  schedule:
    # Run Monday at 8:00 AM Mountain Time (3:00 PM UTC Monday)
    - cron: '0 15 * * 1'
  workflow_dispatch:  # Allow manual triggering

jobs:
  send-notification:
    name: Send Weekly Report Notification
    runs-on: ubuntu-latest
    steps:
      - name: Download latest scan results
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: weekly-aws-resource-monitor.yml
          name: weekly-scan-results
          path: scan-results/
          search_artifacts: true
          if_no_artifact_found: fail

      - name: Send detailed Slack notification
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          # Load results from artifacts
          DEV_RESULTS=$(cat scan-results/dev.json)
          STAGE_RESULTS=$(cat scan-results/stage.json)
          PROD_RESULTS=$(cat scan-results/prod.json)
          STATUS=$(cat scan-results/status.json)
          SCAN_RUN_ID=$(cat scan-results/run_id.txt)

          DEV_STATUS=$(echo "$STATUS" | jq -r '.dev')
          STAGE_STATUS=$(echo "$STATUS" | jq -r '.stage')
          PROD_STATUS=$(echo "$STATUS" | jq -r '.prod')

          # Function to calculate percentage
          calc_percent() {
            local num=$1
            local denom=$2
            if [ "$denom" -eq 0 ]; then
              echo "0"
            else
              echo "scale=1; ($num * 100) / $denom" | bc
            fi
          }

          # Function to format environment results
          format_env_results() {
            local env_name=$1
            local results=$2
            local status=$3

            if [ "$status" != "success" ] || [ -z "$results" ] || [ "$results" == "null" ]; then
              echo "*${env_name} Scan:* :x: Failed to retrieve results"
              return
            fi

            # Parse JSON values
            lambda_total=$(echo "$results" | jq -r ".${env_name,,}.lambda.total_functions // 0")
            lambda_bloated=$(echo "$results" | jq -r ".${env_name,,}.lambda.version_bloat_count // 0")
            lambda_unused=$(echo "$results" | jq -r ".${env_name,,}.lambda.unused_count // 0")
            lambda_storage=$(echo "$results" | jq -r ".${env_name,,}.lambda.total_storage_gb // 0")
            lambda_limit=$(echo "$results" | jq -r ".${env_name,,}.lambda.storage_limit_gb // 300")
            iam_total=$(echo "$results" | jq -r ".${env_name,,}.iam.total_roles // 0")
            iam_quota=$(echo "$results" | jq -r ".${env_name,,}.iam.roles_quota // 1000")
            rds_underused=$(echo "$results" | jq -r ".${env_name,,}.rds.underused_count // 0")
            rds_total=$(echo "$results" | jq -r ".${env_name,,}.rds.total_instances // 0")
            logs_old=$(echo "$results" | jq -r ".${env_name,,}.logs.old_log_groups_count // 0")
            logs_total=$(echo "$results" | jq -r ".${env_name,,}.logs.total_log_groups // 0")

            # Calculate percentages
            iam_percent=$(calc_percent $iam_total $iam_quota)
            lambda_storage_percent=$(calc_percent ${lambda_storage%.*} $lambda_limit)
            lambda_bloat_percent=$(calc_percent $lambda_bloated $lambda_total)
            lambda_unused_percent=$(calc_percent $lambda_unused $lambda_total)
            rds_percent=$(calc_percent $rds_underused $rds_total)
            logs_percent=$(calc_percent $logs_old $logs_total)

            echo "*${env_name} Scan:*"
            echo "• IAM Roles: ${iam_percent}% of 100% (${iam_total}/${iam_quota})"
            echo "• Lambda Storage: ${lambda_storage_percent}% of 100% (${lambda_storage}/${lambda_limit} GB)"
            echo "• Bloated Lambdas: ${lambda_bloat_percent}% (${lambda_bloated}/${lambda_total})"
            echo "• Unused Lambdas: ${lambda_unused_percent}% (${lambda_unused}/${lambda_total})"
            echo "• Underused RDS: ${rds_percent}% (${rds_underused}/${rds_total})"
            echo "• Old CloudWatch Logs: ${logs_percent}% (${logs_old}/${logs_total})"
          }

          # Build message for each environment
          DEV_MSG=$(format_env_results "DEV" "$DEV_RESULTS" "$DEV_STATUS")
          STAGE_MSG=$(format_env_results "STAGE" "$STAGE_RESULTS" "$STAGE_STATUS")
          PROD_MSG=$(format_env_results "PROD" "$PROD_RESULTS" "$PROD_STATUS")

          # Determine overall status
          if [ "$DEV_STATUS" == "success" ] && [ "$STAGE_STATUS" == "success" ] && [ "$PROD_STATUS" == "success" ]; then
            HEADER=":chart_with_upwards_trend: Weekly AWS Resource Monitor Report"
            COLOR="good"
          else
            HEADER=":warning: Weekly AWS Resource Monitor Report - Some Environments Failed"
            COLOR="warning"
          fi

          # Create the Slack message using blocks for better formatting
          cat > /tmp/slack_payload.json << 'PAYLOAD_EOF'
          {
            "blocks": [
              {
                "type": "header",
                "text": {
                  "type": "plain_text",
                  "text": "HEADER_PLACEHOLDER",
                  "emoji": true
                }
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*Report Date:* TIMESTAMP_PLACEHOLDER"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "DEV_PLACEHOLDER"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "STAGE_PLACEHOLDER"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "PROD_PLACEHOLDER"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "context",
                "elements": [
                  {
                    "type": "mrkdwn",
                    "text": ":information_source: *Definitions:* Bloated Lambdas = >10 versions | Underused RDS = avg CPU <10% (7 days) | Old Logs = inactive >12 months"
                  }
                ]
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*:bulb: Recommendations:*\n• *Delete unused IAM roles* to stay within quota limits and improve security posture\n• *Clean up old Lambda versions* - keep only 2-3 recent versions to reduce storage bloat\n• *Delete unused CloudWatch log groups* (>12 months old) to reduce storage costs\n• *Review underused RDS instances* - consider downsizing or consolidating\n  └ <https://app.datadoghq.com/dashboard/9ij-isf-e39/overprovisioned-rds?fromUser=false&offset=0&refresh_mode=yearly&from_ts=1767254400000&to_ts=1767628625022&live=true|View Overprovisioned RDS Dashboard>"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*:moneybag: Understanding AWS Costs:*\n• To understand the cost on AWS resources, please use AWS Cost Explorer\n  └ <https://guild-education.atlassian.net/wiki/spaces/DEVOPS/pages/4582638174/AWS+Cost+Explorer+How+to+Analyze+Cloud+Costs|AWS Cost Explorer Guide>\n• To understand the cost on RDS particularly, refer to this Datadog dashboard\n  └ <https://app.datadoghq.com/cost/analyze/explorer?query=sum%3Aaws.cost.net.amortized.shared.resources.allocated%7Bservicename%3Ards%20AND%20aws_usage_type%3AUSW2-ExtendedSupport%3A%2A%20AND%20aws_cost_type%20IN%20%28Usage%2CDiscountedUsage%2CSavingsPlanCoveredUsage%29%20AND%20NOT%20aws_product%3Asupportenterprise%7D%20by%20%7Bteam%7D.rollup%28sum%2C%20weekly%29&anomaliesOnly=false&displayType=bars&filterRecent=false&measureType=absolute&tableViewType=breakdown&timeframeRefreshMode=paused&start=1756684800000&end=1765497599000&paused=true|RDS Cost Analysis by Team>"
                }
              },
              {
                "type": "divider"
              },
              {
                "type": "context",
                "elements": [
                  {
                    "type": "mrkdwn",
                    "text": "GITHUB_LINK_PLACEHOLDER"
                  }
                ]
              }
            ]
          }
          PAYLOAD_EOF

          # Replace placeholders
          TIMESTAMP=$(TZ='America/Denver' date '+%Y-%m-%d %H:%M:%S %Z')
          GITHUB_LINK="<${{ github.server_url }}/${{ github.repository }}/actions/runs/${SCAN_RUN_ID}|View scan workflow run>"

          # Use jq to properly escape and replace values
          # Block indices: 0=header, 1=date, 2=divider, 3=dev, 4=divider, 5=stage, 6=divider, 7=prod, 8=divider, 9=definitions, 10=divider, 11=recommendations, 12=divider, 13=costs, 14=divider, 15=github_link
          jq --arg header "$HEADER" \
             --arg timestamp "$TIMESTAMP" \
             --arg dev "$DEV_MSG" \
             --arg stage "$STAGE_MSG" \
             --arg prod "$PROD_MSG" \
             --arg github_link "$GITHUB_LINK" \
             '.blocks[0].text.text = $header |
              .blocks[1].text.text = ("*Report Date:* " + $timestamp) |
              .blocks[3].text.text = $dev |
              .blocks[5].text.text = $stage |
              .blocks[7].text.text = $prod |
              .blocks[15].elements[0].text = $github_link' \
             /tmp/slack_payload.json > /tmp/slack_final.json

          # Send to Slack
          curl -X POST "$SLACK_WEBHOOK" \
            -H 'Content-Type: application/json' \
            -d @/tmp/slack_final.json
